#!/usr/bin/env python3
"""
SQLite Viewer et Export Tool pour TLDR_robot
Consultez et exportez vos donn√©es facilement
"""

import sqlite3
import json
import csv
from pathlib import Path
from datetime import datetime
from typing import List, Dict, Any
import logging

# Configuration du logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class TLDRSQLiteViewer:
    """Visualiseur et exporteur pour la base SQLite TLDR"""
    
    def __init__(self, db_path: str = "data/tldr_database.db"):
        self.db_path = Path(db_path)
        if not self.db_path.exists():
            raise FileNotFoundError(f"‚ùå Base de donn√©es non trouv√©e: {db_path}")
        
        logger.info(f"üìä Connexion √† la base: {self.db_path}")
    
    def get_statistics(self) -> Dict[str, Any]:
        """R√©cup√®re les statistiques compl√®tes de la base"""
        try:
            with sqlite3.connect(self.db_path) as conn:
                cursor = conn.cursor()
                
                # Statistiques g√©n√©rales
                cursor.execute("SELECT COUNT(*) FROM articles")
                total_articles = cursor.fetchone()[0]
                
                cursor.execute("SELECT COUNT(*) FROM syntheses")
                total_syntheses = cursor.fetchone()[0]
                
                cursor.execute("SELECT COUNT(*) FROM rapports")
                total_rapports = cursor.fetchone()[0]
                
                # Articles par newsletter type
                cursor.execute('''
                    SELECT newsletter_type, COUNT(*) 
                    FROM articles 
                    GROUP BY newsletter_type
                    ORDER BY COUNT(*) DESC
                ''')
                articles_by_type = dict(cursor.fetchall())
                
                # Articles par date (derniers 30 jours)
                cursor.execute('''
                    SELECT date_extraction, COUNT(*) 
                    FROM articles 
                    WHERE date_extraction >= date('now', '-30 days')
                    GROUP BY date_extraction 
                    ORDER BY date_extraction DESC
                ''')
                recent_articles = dict(cursor.fetchall())
                
                # Cat√©gories les plus fr√©quentes
                cursor.execute("SELECT categories_ia FROM articles WHERE categories_ia IS NOT NULL")
                all_categories = []
                for row in cursor.fetchall():
                    try:
                        cats = json.loads(row[0])
                        all_categories.extend(cats)
                    except:
                        continue
                
                from collections import Counter
                top_categories = dict(Counter(all_categories).most_common(10))
                
                # Synth√®ses r√©centes
                cursor.execute('''
                    SELECT date_synthese, newsletter_type, nb_articles 
                    FROM syntheses 
                    ORDER BY created_at DESC 
                    LIMIT 10
                ''')
                recent_syntheses = cursor.fetchall()
                
                # Taille de la base
                db_size_mb = self.db_path.stat().st_size / (1024 * 1024)
                
                return {
                    'total_articles': total_articles,
                    'total_syntheses': total_syntheses,
                    'total_rapports': total_rapports,
                    'articles_by_type': articles_by_type,
                    'recent_articles': recent_articles,
                    'top_categories': top_categories,
                    'recent_syntheses': recent_syntheses,
                    'db_size_mb': round(db_size_mb, 2),
                    'db_path': str(self.db_path)
                }
                
        except Exception as e:
            logger.error(f"‚ùå Erreur r√©cup√©ration statistiques: {e}")
            return {}
    
    def search_articles(self, query: str, limit: int = 20) -> List[Dict]:
        """Recherche dans les articles"""
        try:
            with sqlite3.connect(self.db_path) as conn:
                conn.row_factory = sqlite3.Row
                cursor = conn.cursor()
                
                cursor.execute('''
                    SELECT * FROM articles 
                    WHERE titre LIKE ? OR resume_tldr LIKE ? 
                    ORDER BY created_at DESC 
                    LIMIT ?
                ''', (f'%{query}%', f'%{query}%', limit))
                
                results = []
                for row in cursor.fetchall():
                    result = dict(row)
                    # Parser les cat√©gories JSON
                    try:
                        result['categories_ia'] = json.loads(result['categories_ia']) if result['categories_ia'] else []
                    except:
                        result['categories_ia'] = []
                    results.append(result)
                
                return results
                
        except Exception as e:
            logger.error(f"‚ùå Erreur recherche: {e}")
            return []
    
    def get_articles_by_date(self, date_str: str) -> List[Dict]:
        """R√©cup√®re tous les articles d'une date donn√©e"""
        try:
            with sqlite3.connect(self.db_path) as conn:
                conn.row_factory = sqlite3.Row
                cursor = conn.cursor()
                
                cursor.execute('''
                    SELECT * FROM articles 
                    WHERE date_extraction = ? 
                    ORDER BY created_at
                ''', (date_str,))
                
                results = []
                for row in cursor.fetchall():
                    result = dict(row)
                    try:
                        result['categories_ia'] = json.loads(result['categories_ia']) if result['categories_ia'] else []
                    except:
                        result['categories_ia'] = []
                    results.append(result)
                
                return results
                
        except Exception as e:
            logger.error(f"‚ùå Erreur r√©cup√©ration articles par date: {e}")
            return []
    
    def get_synthesis_by_date(self, date_str: str) -> Dict:
        """R√©cup√®re la synth√®se d'une date donn√©e"""
        try:
            with sqlite3.connect(self.db_path) as conn:
                conn.row_factory = sqlite3.Row
                cursor = conn.cursor()
                
                cursor.execute('''
                    SELECT * FROM syntheses 
                    WHERE date_synthese = ? 
                    ORDER BY created_at DESC 
                    LIMIT 1
                ''', (date_str,))
                
                row = cursor.fetchone()
                return dict(row) if row else {}
                
        except Exception as e:
            logger.error(f"‚ùå Erreur r√©cup√©ration synth√®se: {e}")
            return {}
    
    def export_to_json(self, output_file: str = None) -> str:
        """Exporte toute la base en JSON"""
        if not output_file:
            output_file = f"tldr_export_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        
        try:
            with sqlite3.connect(self.db_path) as conn:
                conn.row_factory = sqlite3.Row
                cursor = conn.cursor()
                
                # R√©cup√©rer toutes les donn√©es
                cursor.execute("SELECT * FROM articles ORDER BY created_at")
                articles = []
                for row in cursor.fetchall():
                    article = dict(row)
                    try:
                        article['categories_ia'] = json.loads(article['categories_ia']) if article['categories_ia'] else []
                    except:
                        article['categories_ia'] = []
                    articles.append(article)
                
                cursor.execute("SELECT * FROM syntheses ORDER BY created_at")
                syntheses = [dict(row) for row in cursor.fetchall()]
                
                cursor.execute("SELECT * FROM rapports ORDER BY created_at")
                rapports = []
                for row in cursor.fetchall():
                    rapport = dict(row)
                    try:
                        rapport['erreurs'] = json.loads(rapport['erreurs']) if rapport['erreurs'] else []
                    except:
                        rapport['erreurs'] = []
                    rapports.append(rapport)
                
                # Pr√©parer l'export
                export_data = {
                    'export_date': datetime.now().isoformat(),
                    'statistics': self.get_statistics(),
                    'articles': articles,
                    'syntheses': syntheses,
                    'rapports': rapports
                }
                
                # Sauvegarder
                export_path = Path(output_file)
                with open(export_path, 'w', encoding='utf-8') as f:
                    json.dump(export_data, f, indent=2, ensure_ascii=False)
                
                logger.info(f"‚úÖ Export JSON cr√©√©: {export_path}")
                logger.info(f"üìä Contenu: {len(articles)} articles, {len(syntheses)} synth√®ses, {len(rapports)} rapports")
                return str(export_path)
                
        except Exception as e:
            logger.error(f"‚ùå Erreur export JSON: {e}")
            return ""
    
    def export_articles_to_csv(self, output_file: str = None) -> str:
        """Exporte les articles en CSV"""
        if not output_file:
            output_file = f"tldr_articles_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv"
        
        try:
            with sqlite3.connect(self.db_path) as conn:
                conn.row_factory = sqlite3.Row
                cursor = conn.cursor()
                
                cursor.execute("SELECT * FROM articles ORDER BY created_at")
                
                export_path = Path(output_file)
                with open(export_path, 'w', newline='', encoding='utf-8') as csvfile:
                    writer = csv.writer(csvfile)
                    
                    # En-t√™tes
                    writer.writerow([
                        'ID', 'Titre', 'URL', 'R√©sum√©', '√âtat', 'Cat√©gories', 
                        'Dur√©e Lecture', 'Date Extraction', 'Source', 'Newsletter Type', 'Date Cr√©ation'
                    ])
                    
                    # Donn√©es
                    for row in cursor.fetchall():
                        try:
                            categories = json.loads(row['categories_ia']) if row['categories_ia'] else []
                            categories_str = ', '.join(categories)
                        except:
                            categories_str = ''
                        
                        writer.writerow([
                            row['id'],
                            row['titre'],
                            row['url'],
                            row['resume_tldr'],
                            row['etat'],
                            categories_str,
                            row['duree_lecture'],
                            row['date_extraction'],
                            row['source'],
                            row['newsletter_type'],
                            row['created_at']
                        ])
                
                logger.info(f"‚úÖ Export CSV cr√©√©: {export_path}")
                return str(export_path)
                
        except Exception as e:
            logger.error(f"‚ùå Erreur export CSV: {e}")
            return ""
    
    def display_statistics(self):
        """Affiche les statistiques de mani√®re format√©e"""
        stats = self.get_statistics()
        
        if not stats:
            print("‚ùå Impossible de r√©cup√©rer les statistiques")
            return
        
        print("üìä STATISTIQUES DE LA BASE TLDR")
        print("=" * 60)
        print(f"üìÅ Base de donn√©es: {stats['db_path']}")
        print(f"üíæ Taille: {stats['db_size_mb']} MB")
        print()
        
        print("üìà TOTAUX:")
        print(f"   üì∞ Articles: {stats['total_articles']}")
        print(f"   üìä Synth√®ses: {stats['total_syntheses']}")
        print(f"   üìã Rapports: {stats['total_rapports']}")
        print()
        
        if stats['articles_by_type']:
            print("üì∞ ARTICLES PAR TYPE:")
            for newsletter_type, count in stats['articles_by_type'].items():
                print(f"   {newsletter_type}: {count}")
            print()
        
        if stats['top_categories']:
            print("üè∑Ô∏è TOP CAT√âGORIES:")
            for category, count in list(stats['top_categories'].items())[:5]:
                print(f"   {category}: {count}")
            print()
        
        if stats['recent_articles']:
            print("üìÖ ARTICLES R√âCENTS (par date):")
            for date_str, count in list(stats['recent_articles'].items())[:7]:
                print(f"   {date_str}: {count} articles")
            print()
        
        if stats['recent_syntheses']:
            print("üìä SYNTH√àSES R√âCENTES:")
            for date_synthese, newsletter_type, nb_articles in stats['recent_syntheses'][:5]:
                print(f"   {date_synthese} ({newsletter_type}): {nb_articles} articles")
        
        print("=" * 60)
    
    def interactive_search(self):
        """Interface de recherche interactive"""
        print("\nüîç RECHERCHE INTERACTIVE")
        print("Tapez votre requ√™te (ou 'quit' pour quitter):")
        
        while True:
            try:
                query = input("\nüîç Recherche> ").strip()
                
                if query.lower() in ['quit', 'exit', 'q']:
                    break
                
                if not query:
                    continue
                
                results = self.search_articles(query, limit=10)
                
                if results:
                    print(f"\n‚úÖ {len(results)} r√©sultat(s) trouv√©(s):")
                    print("-" * 80)
                    
                    for i, article in enumerate(results, 1):
                        categories = ', '.join(article['categories_ia']) if article['categories_ia'] else 'Aucune'
                        print(f"{i}. {article['titre'][:60]}...")
                        print(f"   üìÖ {article['date_extraction']} | üè∑Ô∏è {categories}")
                        print(f"   üîó {article['url'][:60]}...")
                        if article['resume_tldr']:
                            print(f"   üìù {article['resume_tldr'][:100]}...")
                        print()
                else:
                    print("‚ùå Aucun r√©sultat trouv√©")
                    
            except KeyboardInterrupt:
                break
        
        print("üëã Recherche termin√©e")
    
    def show_daily_summary(self, date_str: str):
        """Affiche le r√©sum√© d'une journ√©e"""
        print(f"\nüìÖ R√âSUM√â DU {date_str}")
        print("=" * 60)
        
        # Articles
        articles = self.get_articles_by_date(date_str)
        if articles:
            print(f"üì∞ {len(articles)} articles trouv√©s:")
            for i, article in enumerate(articles, 1):
                categories = ', '.join(article['categories_ia']) if article['categories_ia'] else 'Aucune'
                print(f"   {i}. {article['titre'][:50]}...")
                print(f"      üè∑Ô∏è {categories} | üîó {article['url'][:40]}...")
            print()
        else:
            print("‚ùå Aucun article trouv√© pour cette date")
        
        # Synth√®se
        synthesis = self.get_synthesis_by_date(date_str)
        if synthesis:
            print("üìä SYNTH√àSE DU JOUR:")
            print(f"   üìù {synthesis['contenu'][:200]}...")
            print(f"   ‚è±Ô∏è Temps de traitement: {synthesis.get('temps_traitement', 0)}s")
            print()
        else:
            print("‚ùå Aucune synth√®se trouv√©e pour cette date")
        
        print("=" * 60)


def main():
    """Interface en ligne de commande"""
    import sys
    
    print("üöÄ TLDR SQLite Viewer & Export Tool")
    print("=" * 50)
    
    # Chemin de la base
    db_path = "data/tldr_database.db"
    if len(sys.argv) > 1:
        db_path = sys.argv[1]
    
    try:
        viewer = TLDRSQLiteViewer(db_path)
        
        if len(sys.argv) == 1:
            # Mode interactif
            print("Mode interactif - Choisissez une option:")
            print("1. Afficher les statistiques")
            print("2. Recherche interactive")
            print("3. Exporter en JSON")
            print("4. Exporter articles en CSV")
            print("5. R√©sum√© d'une journ√©e")
            
            choice = input("\nVotre choix (1-5): ").strip()
            
            if choice == "1":
                viewer.display_statistics()
            
            elif choice == "2":
                viewer.interactive_search()
            
            elif choice == "3":
                output = input("Nom du fichier JSON (ou Entr√©e pour auto): ").strip()
                file_path = viewer.export_to_json(output if output else None)
                if file_path:
                    print(f"‚úÖ Export cr√©√©: {file_path}")
            
            elif choice == "4":
                output = input("Nom du fichier CSV (ou Entr√©e pour auto): ").strip()
                file_path = viewer.export_articles_to_csv(output if output else None)
                if file_path:
                    print(f"‚úÖ Export cr√©√©: {file_path}")
            
            elif choice == "5":
                date_str = input("Date (YYYY-MM-DD): ").strip()
                viewer.show_daily_summary(date_str)
            
            else:
                print("‚ùå Choix invalide")
        
        else:
            # Mode commande
            command = sys.argv[2] if len(sys.argv) > 2 else "stats"
            
            if command == "stats":
                viewer.display_statistics()
            
            elif command == "search":
                query = sys.argv[3] if len(sys.argv) > 3 else ""
                if query:
                    results = viewer.search_articles(query)
                    print(f"üîç R√©sultats pour '{query}': {len(results)} articles")
                    for article in results[:5]:
                        print(f"‚Ä¢ {article['titre']}")
                else:
                    print("‚ùå Requ√™te manquante")
            
            elif command == "export-json":
                output = sys.argv[3] if len(sys.argv) > 3 else None
                file_path = viewer.export_to_json(output)
                if file_path:
                    print(f"‚úÖ Export JSON: {file_path}")
            
            elif command == "export-csv":
                output = sys.argv[3] if len(sys.argv) > 3 else None
                file_path = viewer.export_articles_to_csv(output)
                if file_path:
                    print(f"‚úÖ Export CSV: {file_path}")
            
            elif command == "day":
                date_str = sys.argv[3] if len(sys.argv) > 3 else datetime.now().strftime('%Y-%m-%d')
                viewer.show_daily_summary(date_str)
            
            else:
                print("‚ùå Commande inconnue")
                print("Commandes disponibles: stats, search, export-json, export-csv, day")
    
    except FileNotFoundError as e:
        print(f"‚ùå {e}")
        print("üí° Assurez-vous que l'automatisation a √©t√© ex√©cut√©e au moins une fois")
    except Exception as e:
        print(f"‚ùå Erreur: {e}")


if __name__ == "__main__":
    print("Usage:")
    print("  python sqlite_viewer.py                           # Mode interactif")
    print("  python sqlite_viewer.py [db_path] stats           # Statistiques")
    print("  python sqlite_viewer.py [db_path] search [query]  # Recherche")
    print("  python sqlite_viewer.py [db_path] export-json     # Export JSON")
    print("  python sqlite_viewer.py [db_path] export-csv      # Export CSV")
    print("  python sqlite_viewer.py [db_path] day [date]      # R√©sum√© journ√©e")
    print()
    
    main()